{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pg_curl_worker Documentation : https://supabase.github.io/pg_curl_worker Source Code : https://github.com/supabase/pg_curl_worker A PostgreSQL extension providing an async networking interface accessible via SQL using a background worker and curl.","title":"Welcome"},{"location":"#pg_curl_worker","text":"Documentation : https://supabase.github.io/pg_curl_worker Source Code : https://github.com/supabase/pg_curl_worker A PostgreSQL extension providing an async networking interface accessible via SQL using a background worker and curl.","title":"pg_curl_worker"},{"location":"api/","text":"Creating the All examples assume pg_curl_worker are created in a schema named net . HTTP net.async_get Create an async HTTP GET request returning a bigint id that can be used to retrieve the result. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 begin ; select net . async_get ( 'http://supabase.io' ); async_get ----------- 1 ( 1 row ) select id , url from net . request_queue ; id | url ----+-------------------- 1 | http : // supabase . io ( 1 row ) rollback net.cancel_request Given an id produced from calling an async_get / async_post /etc, cancel the request. If the request was already completed, its result will no longer be retrievable. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 begin ; with req as ( select net . async_get ( 'net://supabase.io' ) as id ) select net . cancel_request ( id ) from req ; cancel_request ---------------- 2 ( 1 row ) select id , url from net . request_queue ; id | url ----+----- ( 0 rows ) rollback ; net.is_complete Given an id produced from calling an async_get / async_post /etc, check if the request has been completed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 begin ; with req as ( select net . async_get ( 'net://supabase.io' ) as id ) select net . is_complete ( id ) from req ; is_complete ------------- f ( 1 row ) rollback ;","title":"API Reference"},{"location":"api/#http","text":"","title":"HTTP"},{"location":"api/#netasync_get","text":"Create an async HTTP GET request returning a bigint id that can be used to retrieve the result. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 begin ; select net . async_get ( 'http://supabase.io' ); async_get ----------- 1 ( 1 row ) select id , url from net . request_queue ; id | url ----+-------------------- 1 | http : // supabase . io ( 1 row ) rollback","title":"net.async_get"},{"location":"api/#netcancel_request","text":"Given an id produced from calling an async_get / async_post /etc, cancel the request. If the request was already completed, its result will no longer be retrievable. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 begin ; with req as ( select net . async_get ( 'net://supabase.io' ) as id ) select net . cancel_request ( id ) from req ; cancel_request ---------------- 2 ( 1 row ) select id , url from net . request_queue ; id | url ----+----- ( 0 rows ) rollback ;","title":"net.cancel_request"},{"location":"api/#netis_complete","text":"Given an id produced from calling an async_get / async_post /etc, check if the request has been completed. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 begin ; with req as ( select net . async_get ( 'net://supabase.io' ) as id ) select net . is_complete ( id ) from req ; is_complete ------------- f ( 1 row ) rollback ;","title":"net.is_complete"},{"location":"contributing/","text":"pg_curl_worker is OSS. PR and issues are welcome. Development Nix is required to set up the environment. Testing For testing locally, execute: 1 2 3 4 5 6 7 8 # might take a while in downloading all the dependencies $ nix-shell # test on pg 12 $ curl-with-pg-12 make installcheck # test on pg 13 $ curl-with-pg-13 make installcheck Documentation All public API must be documented. Building documentation requires python 3.6+ Install Dependencies Install mkdocs, themes, and extensions. 1 pip install -r docs/requirements_docs.txt Serving To serve the documentation locally run 1 mkdocs serve and visit the docs at http://127.0.0.1:8000/pg_curl_worker/","title":"Contributing"},{"location":"contributing/#development","text":"Nix is required to set up the environment.","title":"Development"},{"location":"contributing/#testing","text":"For testing locally, execute: 1 2 3 4 5 6 7 8 # might take a while in downloading all the dependencies $ nix-shell # test on pg 12 $ curl-with-pg-12 make installcheck # test on pg 13 $ curl-with-pg-13 make installcheck","title":"Testing"},{"location":"contributing/#documentation","text":"All public API must be documented. Building documentation requires python 3.6+","title":"Documentation"},{"location":"contributing/#install-dependencies","text":"Install mkdocs, themes, and extensions. 1 pip install -r docs/requirements_docs.txt","title":"Install Dependencies"},{"location":"contributing/#serving","text":"To serve the documentation locally run 1 mkdocs serve and visit the docs at http://127.0.0.1:8000/pg_curl_worker/","title":"Serving"},{"location":"installation/","text":"Tested to work on PostgreSQL 12 and 13. Setup Server Clone this repo and run 1 make && make install To make the extension available to the database add on postgresql.conf : 1 shared_preload_libraries = 'curl_worker' Database To enable the extension in PostgreSQL we must execute a create extension statement. The extension creates its own schema/namespace named net to avoid naming conflicts. 1 create extension pg_curl_worker ;","title":"Installation"},{"location":"installation/#setup","text":"","title":"Setup"},{"location":"installation/#server","text":"Clone this repo and run 1 make && make install To make the extension available to the database add on postgresql.conf : 1 shared_preload_libraries = 'curl_worker'","title":"Server"},{"location":"installation/#database","text":"To enable the extension in PostgreSQL we must execute a create extension statement. The extension creates its own schema/namespace named net to avoid naming conflicts. 1 create extension pg_curl_worker ;","title":"Database"},{"location":"roadmap/","text":"Roadmap [ ] Create a requests table and populate it [ ] Read rows from the requests table inside the background worker(use postgres SPI ) [ ] Create a curl multi handle for each of the rows and make the requests","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"[ ] Create a requests table and populate it [ ] Read rows from the requests table inside the background worker(use postgres SPI ) [ ] Create a curl multi handle for each of the rows and make the requests","title":"Roadmap"}]}